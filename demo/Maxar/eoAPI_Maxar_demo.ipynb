{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0eb29a0",
   "metadata": {},
   "source": [
    "## eoAPI Demo\n",
    "\n",
    "\n",
    "### Background\n",
    "\n",
    "This notebook will review the different [eoAPI](https://github.com/developmentseed/eoAPI) services using the Open data from Maxar.\n",
    "\n",
    "### Objective\n",
    "\n",
    "This notebook aims to demonstrate how [eoAPI](https://github.com/developmentseed/eoAPI) can be used to analyze Maxar's high-resolution satellite data to assess the Kahramanmaras earthquakes' impact.\n",
    "\n",
    "### Maxar Open Data\n",
    "\n",
    "Pre and post-event high-resolution satellite imagery in support of emergency planning, risk assessment, monitoring of staging areas and emergency response, damage assessment, and recovery. These images are generated using the Maxar ARD pipeline, tiled on an organized grid in analysis-ready cloud-optimized formats.\n",
    "\n",
    "### STAC and COGs\n",
    "\n",
    "Maxar releases open data for select sudden-onset major crisis events. In addition to making the data (as nice COGs) freely available on AWS, they also add STAC (static) metadata alongside the images. Having the STAC items already created makes ingestion into the PgSTAC database easy (we don't have to produce the items ourselves and thus have to read the images).\n",
    "\n",
    "To learn more about ingesting the Maxar OpenData STAC catalog into PgSTAC see https://github.com/vincentsarago/MAXAR_opendata_to_pgstac.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fc106d",
   "metadata": {},
   "source": [
    "# Start the services\n",
    "\n",
    "- Clone the repository: `git clone https://github.com/developmentseed/eoAPI.git`\n",
    "- Navigate to the project: `cd eoAPI`\n",
    "- Run services with `docker compose up`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83178d04",
   "metadata": {},
   "source": [
    "# Ingest STAC Metadata\n",
    "\n",
    "Link: https://stacspec.org/en\n",
    "\n",
    "Once the services are launched, the first step is to ingest STAC **Collections** and **Items** in the **PgSTAC** Database.\n",
    "\n",
    "**Collections**: https://raw.githubusercontent.com/vincentsarago/MAXAR_opendata_to_pgstac/main/collections_assets.json\n",
    "\n",
    "\n",
    "**Items**: https://raw.githubusercontent.com/vincentsarago/MAXAR_opendata_to_pgstac/main/items_s3.json\n",
    "\n",
    "\n",
    "**Requirements**: `pypgstac==0.8.1`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0decc1f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python -m pip install \"pypgstac[psycopg]==0.8.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69ff0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the collections file\n",
    "!wget https://github.com/vincentsarago/MAXAR_opendata_to_pgstac/raw/main/Maxar/collections.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673bc641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the items file\n",
    "! wget https://github.com/vincentsarago/MAXAR_opendata_to_pgstac/raw/main/Maxar/items.json.zip && unzip items.json.zip && rm -rf items.json.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff01101",
   "metadata": {},
   "source": [
    "#### Use pypgstac to ingest the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af16cb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingest the collections\n",
    "!pypgstac load collections collections.json --dsn postgresql://username:password@0.0.0.0:5439/postgis --method insert_ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7ded3bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ingest the items\n",
    "!pypgstac load items items.json --dsn postgresql://username:password@0.0.0.0:5439/postgis --method insert_ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e4348e",
   "metadata": {},
   "source": [
    "#### Enable `Context` in pgstac (Optional)\n",
    "\n",
    "See https://github.com/stac-utils/pgstac/blob/main/docs/src/pgstac.md#pgstac-settings-variables\n",
    "\n",
    "The PgSTAC Context extension is not enabled by default because it's \"slows\" down the `/search` request but for this Demo we want it enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc3fa136",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg\n",
    "from psycopg import sql\n",
    "\n",
    "with psycopg.connect(\n",
    "    \"postgresql://username:password@0.0.0.0:5439/postgis\", \n",
    "    autocommit=True,\n",
    "    options=\"-c search_path=pgstac,public -c application_name=pgstac\",\n",
    ") as conn:            \n",
    "    with conn.cursor() as cursor:        \n",
    "        # Add CONTEXT=ON\n",
    "        pgstac_settings = \"\"\"\n",
    "        INSERT INTO pgstac_settings (name, value)\n",
    "        VALUES ('context', 'on')\n",
    "        ON CONFLICT ON CONSTRAINT pgstac_settings_pkey DO UPDATE SET value = excluded.value;\"\"\"\n",
    "        cursor.execute(sql.SQL(pgstac_settings))   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36cc240",
   "metadata": {},
   "source": [
    "# STAC Metadata\n",
    "\n",
    "Endpoint: http://127.0.0.1:8081\n",
    "\n",
    "\n",
    "**Requirements**: `httpx ipyleaflet`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a912d28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python -m pip install httpx ipyleaflet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed3efb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import json\n",
    "import httpx\n",
    "\n",
    "import ipyleaflet\n",
    "\n",
    "stac_endpoint = \"http://127.0.0.1:8081\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146cfd71",
   "metadata": {},
   "source": [
    "### Collection\n",
    "\n",
    "If you look in `https://stac.eoapi.dev/collections` response, you'll find one collection for the Kahramanmaras earthquake named `MAXAR_Kahramanmaras_turkey_earthquake_23`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44105f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the collections and find the collection_id associated to the `kahramanmaras` event\n",
    "collections = httpx.get(f\"{stac_endpoint}/collections\").json()\n",
    "collection_names = ([c[\"id\"] for c in collections[\"collections\"]])\n",
    "\n",
    "print(f\"Number of collections: {len(collection_names)}\")\n",
    "print(f\"Collection names: {collection_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7176b3",
   "metadata": {},
   "source": [
    "Lest focus on the data acquired for the M7.8 and M7.5 Kahramanmaras earthquakes in Turkey on February 6, 2023.\n",
    "\n",
    "More on the event: https://www.usgs.gov/news/featured-story/m78-and-m75-kahramanmaras-earthquake-sequence-near-nurdagi-turkey-turkiye\n",
    "\n",
    "\n",
    "Collection's Name: **MAXAR_Kahramanmaras_turkey_earthquake_23**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507f0afd",
   "metadata": {},
   "source": [
    "Let's check the collection's metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f9b550",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_id = \"MAXAR_Kahramanmaras_turkey_earthquake_23\"\n",
    "\n",
    "collection_info = httpx.get(f\"{stac_endpoint}/collections/{collection_id}\").json()\n",
    "\n",
    "print(collection_info)\n",
    "\n",
    "geojson = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": [\n",
    "        {\n",
    "            'type': 'Feature',\n",
    "            'geometry': {\n",
    "                'type': 'Polygon',\n",
    "                'coordinates': [[\n",
    "                    [bbox[0], bbox[1]],\n",
    "                    [bbox[2], bbox[1]],\n",
    "                    [bbox[2], bbox[3]],\n",
    "                    [bbox[0], bbox[3]],\n",
    "                    [bbox[0], bbox[1]],\n",
    "                ]]\n",
    "            },\n",
    "            'properties': {}\n",
    "        }\n",
    "        for bbox in collection_info[\"extent\"][\"spatial\"][\"bbox\"]\n",
    "    ]\n",
    "}\n",
    "\n",
    "mainbbox = collection_info[\"extent\"][\"spatial\"][\"bbox\"][0]\n",
    "\n",
    "m = ipyleaflet.leaflet.Map(\n",
    "    center=((mainbbox[1] + mainbbox[3]) / 2,(mainbbox[0] + mainbbox[2]) / 2),\n",
    "    zoom=7\n",
    ")\n",
    "\n",
    "geo_json = ipyleaflet.leaflet.GeoJSON(data=geojson)\n",
    "m.add_layer(geo_json)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd7a387",
   "metadata": {},
   "source": [
    "Each collection can have spatial and temporal extents. As for the spatial extent, a collection can have multiple temporal extents, but its first one represents the combined min/max of all the intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f425070c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(collection_info[\"extent\"][\"temporal\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa1db99",
   "metadata": {},
   "source": [
    "## Items\n",
    "\n",
    "In this section, we will:\n",
    "\n",
    "- List all items for a specific collection using the `/collections/{collection_id}/items` endpoint\n",
    "- Talk about the `limit` parameter\n",
    "- Visualize all items on a map\n",
    "- Talk about the item metadata\n",
    "\n",
    "- List the Assets available for one Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0870f7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = httpx.get(f\"{stac_endpoint}/collections/{collection_id}/items\").json()\n",
    "\n",
    "\n",
    "print(f\"Nb Items in Db: {items['context']['matched']}\")  # This is only available if CONTEXT=ON\n",
    "print(f\"Returned {len(items['features'])} Items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0efb74",
   "metadata": {},
   "source": [
    "As you can see below, the `/items` endpoints returned only 10 items. To return more data, we need to either use the `paging` mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992501d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kahramanmaras_items = []\n",
    "\n",
    "url = f\"{stac_endpoint}/collections/{collection_id}/items\"\n",
    "while True:\n",
    "    items = httpx.get(url, params={\"limit\": 100}).json()\n",
    "    \n",
    "    kahramanmaras_items.extend(items[\"features\"])\n",
    "    next_link = list(filter(lambda link: link[\"rel\"] == \"next\", items[\"links\"]))\n",
    "    if next_link:\n",
    "        url = next_link[0][\"href\"]\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print(f\"Nb Items: {len(kahramanmaras_items)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f77306d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ipyleaflet.leaflet.Map(\n",
    "    center=((mainbbox[1] + mainbbox[3]) / 2,(mainbbox[0] + mainbbox[2]) / 2),\n",
    "    zoom=7\n",
    ")\n",
    "\n",
    "event_date = datetime(2023, 2, 6, hour=0, minute=0)\n",
    "\n",
    "# Use a styling function to show where we have before/after items\n",
    "def style_function(feature):\n",
    "    d = datetime.strptime(feature[\"properties\"][\"datetime\"], \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    return {\n",
    "        \"fillOpacity\": 0.1,\n",
    "        \"weight\": 0.1,\n",
    "        # Blue for pre-event / red for post-event\n",
    "        \"fillColor\": \"#0000ff\" if d < event_date else \"#ff0000\"\n",
    "    }\n",
    "\n",
    "geo_json = ipyleaflet.leaflet.GeoJSON(data={\"type\": \"FeatureCollection\", \"features\": kahramanmaras_items}, style_callback=style_function)\n",
    "m.add_layer(geo_json)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec55f253",
   "metadata": {},
   "source": [
    "#####  Item metadata \n",
    "\n",
    "Each item should have an `id`, a `geometry`, some links to `Assets`, and a set of properties.\n",
    "\n",
    "Item specification: https://github.com/radiantearth/stac-spec/blob/master/item-spec/item-spec.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ba6e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "item = kahramanmaras_items[0]\n",
    "print(\"Item example:\")\n",
    "print(json.dumps(item, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f632955",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Item Id\", item[\"id\"])\n",
    "print(\"Item Assets:\", list(item[\"assets\"].keys()))\n",
    "print(\"Item Properties:\")\n",
    "print(json.dumps(item[\"properties\"], indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844f4575",
   "metadata": {},
   "source": [
    "#### Find acquisition times\n",
    "\n",
    "Every item should have either a `datetime` or a `start/end_datetime` property. For the Maxar dataset, we are assuming that `datetime` is acquisition times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9013bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetimes = {item[\"properties\"][\"datetime\"] for item in kahramanmaras_items}\n",
    "print(\"Dates:\", sorted(list(datetimes))[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53e73ff",
   "metadata": {},
   "source": [
    "Let's sort the items in two categories: `before` and `after` the event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021248b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_date = datetime(2023, 2, 6, hour=0, minute=0)\n",
    "\n",
    "pre_items = list(\n",
    "    filter(\n",
    "        lambda item: datetime.strptime(item[\"properties\"][\"datetime\"], \"%Y-%m-%dT%H:%M:%SZ\") < event_date, \n",
    "        kahramanmaras_items\n",
    "    )\n",
    ")\n",
    "\n",
    "post_items = list(\n",
    "    filter(\n",
    "        lambda item: datetime.strptime(item[\"properties\"][\"datetime\"], \"%Y-%m-%dT%H:%M:%SZ\") >= event_date, \n",
    "        kahramanmaras_items\n",
    "    )\n",
    ")\n",
    "print(\"PRE event items:\", len(pre_items))\n",
    "print(\"POST event items:\", len(post_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d66896e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same but using the STAC API\n",
    "pre_items_api = httpx.post(\n",
    "    f\"{stac_endpoint}/search\",\n",
    "    data=json.dumps(\n",
    "        {\n",
    "            \"filter-lang\": 'cql2-json',\n",
    "            \"filter\": {\n",
    "                \"op\": 'and', \n",
    "                \"args\": [\n",
    "                    {\n",
    "                        \"op\": \"in\", \n",
    "                        \"args\": [{\"property\": \"collection\"}, [collection_id]]\n",
    "                    },\n",
    "                    {\n",
    "                        \"op\": \"lt\", \n",
    "                        \"args\": [\n",
    "                            {\"property\": \"datetime\"}, \"2023-02-06T00:00:00Z\"\n",
    "                        ]\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "        }\n",
    "    )\n",
    ").json()\n",
    "\n",
    "print(f\"Nb Items in Db: {pre_items_api['context']['matched']}\")  # This is only available if CONTEXT=ON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca2e374",
   "metadata": {},
   "source": [
    "## Asset visualization\n",
    "\n",
    "So we have **2115** items for the `MAXAR_Kahramanmaras_turkey_earthquake_23` collection, and each item has **4** assets (this is also found at the collection level in the `item_assets extension`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca07238",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(item[\"assets\"].keys()))\n",
    "print()\n",
    "for name, asset in item[\"assets\"].items():\n",
    "    print(name, \": \", asset[\"type\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc1a304",
   "metadata": {},
   "source": [
    "In eoAPI, we have a raster API connected to the PgSTAC database. The service is built using [titiler-pgstac](http://github.com/stac-utils/titiler-pgstac) and can be used to visualize `Item` or `Mosaics` (multiple items).\n",
    "\n",
    "Endpoint: [http://127.0.0.1:8082](http://127.0.0.1:8082)\n",
    "\n",
    "We know we have 4 assets for each item, and 3 are of `Cloud-Optimized` type. Let's use the raster API to visualize them.\n",
    "\n",
    "First, let's get the Raster metadata for each `raster` asset. The raster API will use the asset's `type` metadata to filter non-raster dataset (e.g.  `application/geopackage+sqlite3`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dceef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_endpoint = \"http://127.0.0.1:8082\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a45bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching Raster information for all the `raster` assets\n",
    "item_id = item[\"id\"]\n",
    "\n",
    "print(f\"Fetching Raster info for Item {item_id}\")\n",
    "info = httpx.get(f\"{raster_endpoint}/collections/{collection_id}/items/{item_id}/info\").json()\n",
    "\n",
    "print(\"Returned metadata for Assets:\", list(info.keys()))\n",
    "print()\n",
    "print(json.dumps(info[\"visual\"], indent=4))\n",
    "print()\n",
    "for name, asset in info.items():\n",
    "    print(name, asset[\"minzoom\"], asset[\"maxzoom\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a87b045",
   "metadata": {},
   "source": [
    "The `/collections/{collectionId}/items/{itemId}/info` endpoint returned metadata for 3 assets (the raster ones). We now know more about each asset (datatype, zoom levels, number of bands), which can help us create tiles urls.\n",
    "\n",
    "### Asset on Map\n",
    "\n",
    "To visualize an asset on a Map, we need to construct a `Tile URL`. To ease the task we can use the raster's service `/collections/{collection_id}/items/{item_id}/tilejson.json` endpoint, but here are the requirements:\n",
    "\n",
    "- HAVE TO pass `assets` or `expression` parameter\n",
    "- CAN pass `min/max zooms` (which will avoid under/over-zooming)\n",
    "- CAN pass `rescale` parameter if datatype is not compatible with PNG/JPEG output format\n",
    "- CAN pass `asset_bidx` parameter to select band combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71ad07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `visual` Asset\n",
    "tilejson = httpx.get(\n",
    "    f\"{raster_endpoint}/collections/{collection_id}/items/{item_id}/tilejson.json\",\n",
    "    params = (\n",
    "        (\"assets\", \"visual\"),  # THIS PARAMETER IS MANDATORY\n",
    "        (\"minzoom\", 12),  # By default the tiler will use 0\n",
    "        (\"maxzoom\", 19), # By default the tiler will use 24\n",
    "    )\n",
    ").json()\n",
    "print(tilejson)\n",
    "\n",
    "bounds = tilejson[\"bounds\"]\n",
    "m = ipyleaflet.leaflet.Map(\n",
    "    center=((bounds[1] + bounds[3]) / 2,(bounds[0] + bounds[2]) / 2),\n",
    "    zoom=12\n",
    ")\n",
    "\n",
    "geo_json = ipyleaflet.leaflet.GeoJSON(\n",
    "    data=item,\n",
    "    style={\n",
    "        'opacity': 1, 'dashArray': '9', 'fillOpacity': 0., 'weight': 4\n",
    "    }\n",
    ")\n",
    "m.add_layer(geo_json)\n",
    "\n",
    "tiles = ipyleaflet.leaflet.TileLayer(\n",
    "    url=tilejson[\"tiles\"][0],\n",
    "    min_zoom=tilejson[\"minzoom\"],\n",
    "    max_zoom=tilejson[\"maxzoom\"],\n",
    "    bounds=[\n",
    "        [bounds[1], bounds[0]],\n",
    "        [bounds[3], bounds[2]],\n",
    "\n",
    "    ],\n",
    ")\n",
    "\n",
    "m.add_layer(tiles)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a02b6ae",
   "metadata": {},
   "source": [
    "## Mosaics\n",
    "\n",
    "As mentioned and shown with `titiler-pgstac`, we can visualize an item's asset. Still, the raster API's real power is to create a virtual mosaic dynamically and merge multiple items on the fly.\n",
    "\n",
    "Learn more: http://github.com/stac-utils/titiler-pgstac.\n",
    "\n",
    "Let's create `mosaics` for `pre` and `post` events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331929fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_date = \"2023-02-06T00:00:00Z\"\n",
    "\n",
    "\n",
    "# Let's focus on Kahramanmaraş city \n",
    "bounds = [36.83064386785452, 37.53123515817725, 37.03859654890988, 37.63167525356958]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c276ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_mosaic = httpx.post(\n",
    "    f\"{raster_endpoint}/searches/register\",\n",
    "    data=json.dumps(\n",
    "        {\n",
    "            \"filter-lang\": 'cql2-json',\n",
    "            \"filter\": {\n",
    "                \"op\": 'and', \n",
    "                \"args\": [\n",
    "                    {\n",
    "                        \"op\": \"in\", \n",
    "                        \"args\": [{\"property\": \"collection\"}, [collection_id]]\n",
    "                    },\n",
    "                    {\n",
    "                        \"op\": \"lt\", \n",
    "                        \"args\": [\n",
    "                            {\"property\": \"datetime\"}, event_date\n",
    "                        ]\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "            \"sortby\": [\n",
    "                {\n",
    "                    \"field\": \"tile:clouds_percent\",\n",
    "                    \"direction\": \"asc\"\n",
    "                },\n",
    "            ],\n",
    "            \"metadata\":{\n",
    "                \"name\": \"Maxar Kahramanmaras - Pre event\",\n",
    "                \"bounds\": bounds,\n",
    "            }\n",
    "            \n",
    "        }\n",
    "    )\n",
    ").json()\n",
    "\n",
    "post_mosaic = httpx.post(\n",
    "    f\"{raster_endpoint}/searches/register\",\n",
    "    data=json.dumps(\n",
    "        {\n",
    "            \"filter-lang\": 'cql2-json',\n",
    "            \"filter\": {\n",
    "                \"op\": 'and', \n",
    "                \"args\": [\n",
    "                    {\n",
    "                        \"op\": \"in\", \n",
    "                        \"args\": [{\"property\": \"collection\"}, [collection_id]]\n",
    "                    },\n",
    "                    {\n",
    "                        \"op\": \"ge\", \n",
    "                        \"args\": [\n",
    "                            {\"property\": \"datetime\"}, event_date\n",
    "                        ]\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "            \"sortby\": [\n",
    "                {\n",
    "                    \"field\": \"tile:clouds_percent\",\n",
    "                    \"direction\": \"asc\"\n",
    "                },\n",
    "            ],\n",
    "            \"metadata\":{\n",
    "                \"name\": \"Maxar Kahramanmaras - Port event\",\n",
    "                \"bounds\": bounds,\n",
    "            }\n",
    "            \n",
    "        }\n",
    "    )\n",
    ").json()\n",
    "\n",
    "print(\"Pre event Mosaic\")\n",
    "print(json.dumps(pre_mosaic, indent=4))\n",
    "print()\n",
    "print(\"Post event Mosaic\")\n",
    "print(json.dumps(post_mosaic, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd5f539",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "The `mosaic` corresponds to an STAC Search query. Because we use `PgSTAC` backend, we can make use of the `filter` extension to construct complex queries: https://github.com/stac-api-extensions/filter\n",
    "\n",
    "```json\n",
    "{\n",
    "    // PgSTAC accepts multiple languages for filtering; here we will use cql2-json\n",
    "    \"filter-lang\": 'cql2-json',\n",
    "    // We tell PgSTAC to `register` a `search` request with the following filter:\n",
    "    \"filter\": {\n",
    "        \"op\": 'and',\n",
    "        \"args\": [\n",
    "            // Item's collection HAS TO be in `[collection_id]`\n",
    "            {\n",
    "                \"op\": \"in\",\n",
    "                \"args\": [{\"property\": \"collection\"}, [collection_id]]\n",
    "            },\n",
    "            // Filter Items that have datetime `lt` than the event date\n",
    "            {\n",
    "                \"op\": \"lt\",\n",
    "                \"args\": [\n",
    "                    {\"property\": \"datetime\"}, event_date\n",
    "                ]\n",
    "            },\n",
    "            // Sort the items using clouds_percent property to make sure cloudless images are on the top\n",
    "            \"sortby\": [\n",
    "                {\n",
    "                    \"field\": \"tile:clouds_percent\",\n",
    "                    \"direction\": \"asc\"\n",
    "                },\n",
    "            ],\n",
    "            // titiler-pgstac accept some additional metadata\n",
    "            // <https://stac-utils.github.io/titiler-pgstac/advanced/metadata/>\n",
    "            // One is useful: `bounds`. When creating a mosaic, the tiler will have no idea\n",
    "            // where the items will be before trying to create each tile. To avoid trying to request\n",
    "            // tiles where we know we don't have any items, we can add the collection's extent to the\n",
    "            // mosaic metadata.\n",
    "            // The tiler service will then return the bounds in the tilejson document for the\n",
    "            // client application.\n",
    "            \"metadata\":{\n",
    "                \"name\": \"Maxar Kahramanmaras - Pre event\",\n",
    "                \"bounds\": bounds,\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "API Response:\n",
    "\n",
    "The raster service will return a `searchid` hash (`mosaic id`), which we can use to construct a tile URL.\n",
    "\n",
    "To create a valid tile URL, we will again need to pass an `assets` parameter to tell the tiler which assets we want to visualize. We can also set the min/max zoom limits to avoid underzooming (opening too many files) and overzooming.\n",
    "\n",
    "See the complete list of options: https://stac-utils.github.io/titiler-pgstac/mosaic_endpoints/#tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1638c679",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_id = pre_mosaic[\"id\"]\n",
    "\n",
    "tilejson_pre = httpx.get(\n",
    "    f\"{raster_endpoint}/searches/{search_id}/tilejson.json\",\n",
    "    params = (\n",
    "        (\"assets\", \"visual\"),  # THIS IS MANDATORY\n",
    "        (\"minzoom\", 12),\n",
    "        (\"maxzoom\", 19), \n",
    "    )\n",
    ").json()\n",
    "print(tilejson_pre)\n",
    "\n",
    "bounds = tilejson_pre[\"bounds\"]\n",
    "m = ipyleaflet.leaflet.Map(\n",
    "    center=((bounds[1] + bounds[3]) / 2,(bounds[0] + bounds[2]) / 2),\n",
    "    zoom=12\n",
    ")\n",
    "\n",
    "geo_json = ipyleaflet.leaflet.GeoJSON(\n",
    "    data={\"type\": \"FeatureCollection\", \"features\": pre_items}, \n",
    "    style={\n",
    "        \"fillOpacity\": 0,\n",
    "        \"weight\": 1,\n",
    "    },\n",
    ")\n",
    "m.add_layer(geo_json)\n",
    "\n",
    "tiles = ipyleaflet.leaflet.TileLayer(\n",
    "    url=tilejson_pre[\"tiles\"][0],\n",
    "    min_zoom=tilejson_pre[\"minzoom\"],\n",
    "    max_zoom=tilejson_pre[\"maxzoom\"],\n",
    "    bounds=[\n",
    "        [bounds[1], bounds[0]],\n",
    "        [bounds[3], bounds[2]],\n",
    "\n",
    "    ],\n",
    ")\n",
    "\n",
    "m.add_layer(tiles)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74df2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_id = post_mosaic[\"id\"]\n",
    "\n",
    "tilejson_post = httpx.get(\n",
    "    f\"{raster_endpoint}/searches/{search_id}/tilejson.json\",\n",
    "    params = (\n",
    "        (\"assets\", \"visual\"),  # THIS IS MANDATORY\n",
    "        (\"minzoom\", 12),\n",
    "        (\"maxzoom\", 19), \n",
    "    )\n",
    ").json()\n",
    "print(tilejson_post)\n",
    "\n",
    "bounds = tilejson_post[\"bounds\"]\n",
    "m = ipyleaflet.leaflet.Map(\n",
    "    center=((bounds[1] + bounds[3]) / 2,(bounds[0] + bounds[2]) / 2),\n",
    "    zoom=10\n",
    ")\n",
    "\n",
    "geo_json = ipyleaflet.leaflet.GeoJSON(\n",
    "    data={\"type\": \"FeatureCollection\", \"features\": post_items}, \n",
    "    style={\n",
    "        \"fillOpacity\": 0,\n",
    "        \"weight\": 0.5,\n",
    "    },\n",
    ")\n",
    "m.add_layer(geo_json)\n",
    "\n",
    "tiles = ipyleaflet.leaflet.TileLayer(\n",
    "    url=tilejson_post[\"tiles\"][0],\n",
    "    min_zoom=tilejson_post[\"minzoom\"],\n",
    "    max_zoom=tilejson_post[\"maxzoom\"],\n",
    "    bounds=[\n",
    "        [bounds[1], bounds[0]],\n",
    "        [bounds[3], bounds[2]],\n",
    "\n",
    "    ],\n",
    ")\n",
    "\n",
    "m.add_layer(tiles)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d900b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ipyleaflet.leaflet.Map(\n",
    "    center=(37.571788, 36.919100),\n",
    "    zoom=12,\n",
    ")\n",
    "\n",
    "bounds = tilejson_pre[\"bounds\"]\n",
    "before_layer = ipyleaflet.leaflet.TileLayer(\n",
    "    url=tilejson_pre[\"tiles\"][0],\n",
    "    min_zoom=tilejson_pre[\"minzoom\"],\n",
    "    max_zoom=tilejson_pre[\"maxzoom\"],\n",
    "    bounds=[\n",
    "        [bounds[1], bounds[0]],\n",
    "        [bounds[3], bounds[2]],\n",
    "    ],\n",
    ")\n",
    "\n",
    "bounds = tilejson_post[\"bounds\"]\n",
    "after_layer = ipyleaflet.leaflet.TileLayer(\n",
    "    url=tilejson_post[\"tiles\"][0],\n",
    "    min_zoom=tilejson_post[\"minzoom\"],\n",
    "    max_zoom=tilejson_post[\"maxzoom\"],\n",
    "    bounds=[\n",
    "        [bounds[1], bounds[0]],\n",
    "        [bounds[3], bounds[2]],\n",
    "    ],\n",
    ")\n",
    "\n",
    "control = ipyleaflet.leaflet.SplitMapControl(left_layer=before_layer, right_layer=after_layer)\n",
    "m.add_control(control)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9bc02d",
   "metadata": {},
   "source": [
    "## What's Next?\n",
    "\n",
    "### Spin Up Your Own eoAPI Instance\n",
    "\n",
    "You've seen what eoAPI can do with Maxar data in the context of the Turkey Earthquakes. Interested in setting up your own eoAPI service? It's straightforward! Follow the 'Getting Started' section of the [eoAPI GitHub repository](https://github.com/developmentseed/eoAPI) to get your instance up and running. This will give you greater control and customization options.\n",
    "\n",
    "### Contribute Your Data\n",
    "\n",
    "Consider contributing if you've used Maxar data for similar analyses or have other datasets that could benefit the community. Uploading your data to your eoAPI instance can provide more diverse examples and help in various applications.\n",
    "\n",
    "### Community-Driven Examples\n",
    "\n",
    "The examples you see here, including this notebook, are often community-driven. We encourage you to contribute your analyses, workflows, or visualizations. Your insights could be invaluable for helping others.\n",
    "\n",
    "### Have Questions? Join the Discussion!\n",
    "\n",
    "If you have questions, feedback, or want to engage with the eoAPI community, please join the [GitHub discussions](https://github.com/developmentseed/eoAPI/discussions). It's a great place to ask questions, share your experiences, and connect with others interested in eoAPI and its components. \n",
    "\n",
    "---\n",
    "\n",
    "Thank you for taking the time to go through this notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
